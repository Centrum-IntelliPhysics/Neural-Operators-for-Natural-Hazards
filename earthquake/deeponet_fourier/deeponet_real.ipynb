{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G-TdAyUB0JL5"
   },
   "source": [
    "#### Designing a DeepONet framework for mapping the ground acceleration to the structural response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wiytiWyl0JL6",
    "outputId": "a6fe1eea-c14d-4d04-b88c-66444b33bbe4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "import numpy.random as npr\n",
    "from jax import jit, grad, vmap\n",
    "from jax.example_libraries.optimizers import adam\n",
    "from jax import value_and_grad\n",
    "from functools import partial\n",
    "from jax import jacfwd, jacrev\n",
    "import jax.nn as jnn\n",
    "import math\n",
    "from jax import random\n",
    "import jax\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "from flax import linen as nn\n",
    "import sklearn.metrics\n",
    "from jax.lax import conv_general_dilated as conv_lax\n",
    "import argparse\n",
    "import os\n",
    "import time\n",
    "from termcolor import colored\n",
    "from scipy.io import loadmat\n",
    "import scipy.io as io\n",
    "import pickle\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "plt.rcParams.update({'font.size': 9})\n",
    "import seaborn as sns\n",
    "sns.set_style(\"white\")\n",
    "sns.set_style(\"ticks\")\n",
    "\n",
    "# Check where gpu is enable or not\n",
    "from jax.lib import xla_bridge\n",
    "print(xla_bridge.get_backend().platform)\n",
    "\n",
    "cluster = False\n",
    "save = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jaGMlhJl0JL7",
    "outputId": "5db466fa-897f-4405-969f-ad31658b8fa3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "if cluster == True:\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('-seed', dest='seed', type=int, default=0, help='Seed number.')\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # Print all the arguments\n",
    "    for arg in vars(args):\n",
    "        print(f'{arg}: {getattr(args, arg)}')\n",
    "\n",
    "    seed = args.seed\n",
    "\n",
    "if cluster == False:\n",
    "    seed = 0 # Seed number.\n",
    "\n",
    "if save == True:\n",
    "    resultdir = os.path.join(os.getcwd(), 'Results_real')\n",
    "    if not os.path.exists(resultdir):\n",
    "        os.makedirs(resultdir)\n",
    "\n",
    "if save == True and cluster == True:\n",
    "    orig_stdout = sys.stdout\n",
    "    q = open(os.path.join(resultdir, 'outputs.txt'), 'w')\n",
    "    sys.stdout = q\n",
    "    print (\"------START------\")\n",
    "\n",
    "print('seed = '+str(seed))\n",
    "np.random.seed(seed)\n",
    "key = 1234 #random.PRNGKey(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_matrix(matrix, num_subparts=118):\n",
    "    \n",
    "    subpart_size = matrix.shape[1] // num_subparts\n",
    "    divided_matrix = matrix.reshape(matrix.shape[0] * num_subparts, subpart_size)\n",
    "    \n",
    "    return divided_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RVE4R7ox0JL7",
    "outputId": "74110ef4-29c0-4e48-911f-675b537590ca",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "data = loadmat('../data/dataset_EQ_fourier.mat') # Load the .mat file\n",
    "indices = io.loadmat('../data/train_test_index.mat')\n",
    "index_train = indices['train'].T\n",
    "index_test = indices['test'].T\n",
    "\n",
    "inputs_train = data['ground_motion_real'][index_train[:,0]-1,:]\n",
    "outputs_train = data['displacement_real'][index_train[:,0]-1,:]\n",
    "inputs_test = data['ground_motion_real'][index_test[:,0]-1,:]\n",
    "outputs_test = data['displacement_real'][index_test[:,0]-1,:]\n",
    "\n",
    "#inputs_train = divide_matrix(inputs_train)\n",
    "#inputs_test = divide_matrix(inputs_test)\n",
    "#outputs_train = divide_matrix(outputs_train)\n",
    "#outputs_test = divide_matrix(outputs_test)\n",
    "\n",
    "num_train = inputs_train.shape[0]\n",
    "num_test = inputs_test.shape[0]\n",
    "\n",
    "outputs_mean = np.mean(outputs_train, axis=0)\n",
    "outputs_std = np.std(outputs_train, axis=0)\n",
    "outputs_train = (outputs_train - outputs_mean)/outputs_std\n",
    "outputs_test = (outputs_test - outputs_mean)/outputs_std\n",
    "\n",
    "inputs_mean = np.mean(inputs_train, axis=0)\n",
    "inputs_std = np.std(inputs_train, axis=0)\n",
    "inputs_train = (inputs_train - inputs_mean)/inputs_std\n",
    "inputs_test = (inputs_test - inputs_mean)/inputs_std\n",
    "\n",
    "num_t = inputs_train.shape[-1]\n",
    "grid = np.array(np.linspace(0,1,num_t)).reshape(num_t,1)\n",
    "grid = jnp.concatenate([grid, np.cos(2*np.pi*grid), np.sin(2*np.pi*grid), np.cos(4*np.pi*grid), np.sin(4*np.pi*grid)], axis = -1)\n",
    "print(\"Shape of the grid:\", grid.shape)\n",
    "\n",
    "# Check the shapes of the subsets\n",
    "print(\"Shape of inputs_train:\", inputs_train.shape)\n",
    "print(\"Shape of inputs_test:\", inputs_test.shape)\n",
    "print(\"Shape of outputs_train:\", outputs_train.shape)\n",
    "print(\"Shape of outputs_test:\", outputs_test.shape)\n",
    "print('#'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-UHALcEH0JL7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize the Glorot (Xavier) normal distribution for weight initialization\n",
    "initializer = jax.nn.initializers.glorot_normal()\n",
    "\n",
    "def init_glorot_params(layer_sizes, key = random.PRNGKey(seed)):\n",
    "    \"\"\"\n",
    "    Initialize the parameters of the neural network using Glorot (Xavier) initialization.\n",
    "\n",
    "    Args:\n",
    "    layer_sizes (list): List of integers representing the size of each layer.\n",
    "    key (PRNGKey): Random number generator key for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "    list: List of tuples, each containing weights and biases for a layer.\n",
    "    \"\"\"\n",
    "    return [(initializer(key, (m, n), jnp.float32), jnp.zeros(n))\n",
    "            for m, n, in zip(layer_sizes[:-1], layer_sizes[1:])]\n",
    "\n",
    "def BranchNet(params, x):\n",
    "    \"\"\"\n",
    "    Implement the branch network of the DeepONet.\n",
    "\n",
    "    Args:\n",
    "    params (list): List of weight and bias tuples for each layer.\n",
    "    x (array): Input to the branch network.\n",
    "\n",
    "    Returns:\n",
    "    array: Output of the branch network.\n",
    "    \"\"\"\n",
    "    def single_forward(params, x):\n",
    "        for w, b in params:\n",
    "            outputs = jnp.dot(x, w) + b\n",
    "            x = jnn.silu(outputs)\n",
    "        return outputs\n",
    "\n",
    "    return vmap(partial(single_forward, params))(x)\n",
    "\n",
    "def TrunkNet(params, x):\n",
    "    \"\"\"\n",
    "    Implement the trunk network of the DeepONet.\n",
    "\n",
    "    Args:\n",
    "    params (list): List of weight and bias tuples for each layer.\n",
    "    x (float): First input to the trunk network.\n",
    "    t (float): Second input to the trunk network.\n",
    "\n",
    "    Returns:\n",
    "    array: Output of the trunk network.\n",
    "    \"\"\"\n",
    "    inputs = jnp.array(x)\n",
    "    for w, b in params:\n",
    "        outputs = jnp.dot(x, w) + b\n",
    "        x = jnn.silu(outputs)\n",
    "    return outputs\n",
    "\n",
    "@jit\n",
    "def DeepONet(params, branch_inputs, trunk_inputs):\n",
    "    \"\"\"\n",
    "    Implement the complete DeepONet architecture.\n",
    "\n",
    "    Args:\n",
    "    params (tuple): Tuple containing branch and trunk network parameters.\n",
    "    branch_inputs (array): Inputs for the branch network.\n",
    "    trunk_inputs (array): Inputs for the trunk network.\n",
    "\n",
    "    Returns:\n",
    "    array: Output of the DeepONet.\n",
    "    \"\"\"\n",
    "    params_branch, params_trunk = params\n",
    "    branch_outputs = lambda x: BranchNet(params_branch, x)\n",
    "    b_out = branch_outputs(branch_inputs)\n",
    "    trunk_output = lambda y: TrunkNet(params_trunk, y)\n",
    "    t_out = trunk_output(trunk_inputs)\n",
    "    results = jnp.einsum('ik, lk -> il',b_out, t_out)\n",
    "    return results\n",
    "\n",
    "# network parameters.\n",
    "p = 100 # Number of output neurons in both the branch and trunk net outputs.\n",
    "nx = inputs_train.shape[-1]\n",
    "input_neurons_branch = nx # m\n",
    "input_neurons_trunk = grid.shape[-1]\n",
    "\n",
    "layer_sizes_b = [input_neurons_branch] + [100]*6 + [p]\n",
    "layer_sizes_t = [input_neurons_trunk] + [100]*6 + [p]\n",
    "\n",
    "params_branch = init_glorot_params(layer_sizes=layer_sizes_b)\n",
    "params_trunk = init_glorot_params(layer_sizes=layer_sizes_t)\n",
    "\n",
    "params= (params_branch, params_trunk)\n",
    "\n",
    "def objective(params, branch_inputs, trunk_inputs, target_values):\n",
    "    \"\"\"\n",
    "    Define the objective function (loss function) for training.\n",
    "\n",
    "    Args:\n",
    "    params (tuple): Tuple containing branch and trunk network parameters.\n",
    "    branch_inputs (array): Inputs for the branch network.\n",
    "    trunk_inputs (array): Inputs for the trunk network.\n",
    "    target_values (array): True output values to compare against.\n",
    "\n",
    "    Returns:\n",
    "    float: Mean squared error loss.\n",
    "    \"\"\"\n",
    "    predictions = DeepONet(params, branch_inputs, trunk_inputs)\n",
    "    loss_mse = jnp.mean((predictions - target_values)**2)\n",
    "    return loss_mse\n",
    "\n",
    "\n",
    "# Adam optimizer\n",
    "@jit\n",
    "def resnet_update(params, branch_input, trunk_inputs, target_values, opt_state):\n",
    "    \"\"\"\n",
    "    Compute the gradient for a batch and update the parameters.\n",
    "\n",
    "    Args:\n",
    "    params (tuple): Current network parameters.\n",
    "    branch_inputs (array): Inputs for the branch network.\n",
    "    trunk_inputs (array): Inputs for the trunk network.\n",
    "    target_values (array): True output values.\n",
    "    opt_state: Current state of the optimizer.\n",
    "\n",
    "    Returns:\n",
    "    tuple: Updated parameters, updated optimizer state, and current loss value.\n",
    "    \"\"\"\n",
    "    value, grads = value_and_grad(objective)(params, branch_input, trunk_inputs, target_values)\n",
    "    opt_state = opt_update(0, grads, opt_state)\n",
    "    return get_params(opt_state), opt_state, value\n",
    "\n",
    "# Initialize the Adam optimizer\n",
    "opt_init, opt_update, get_params = adam(step_size=1e-3, b1=0.9, b2=0.999, eps=1e-08)\n",
    "opt_state = opt_init(params)\n",
    "\n",
    "bs = 50000 #batch size\n",
    "iteration_list, loss_list, test_loss_list = [], [], []\n",
    "iteration = 0\n",
    "\n",
    "n_epochs = 1000000\n",
    "num_samples = len(inputs_train)\n",
    "\n",
    "# test input preparation\n",
    "branch_inputs_test = inputs_test\n",
    "targets = outputs_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NBe_opRm0JL8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_model_params(params, resultdir, filename='model_params.pkl'):\n",
    "    if not os.path.exists(resultdir):\n",
    "        os.makedirs(resultdir)\n",
    "\n",
    "    save_path = os.path.join(resultdir, filename)\n",
    "    with open(save_path, 'wb') as f:\n",
    "        pickle.dump(params, f)\n",
    "\n",
    "def load_model_params(resultdir, filename='model_params.pkl'):\n",
    "    load_path = os.path.join(resultdir, filename)\n",
    "    with open(load_path, 'rb') as f:\n",
    "        params = pickle.load(f)\n",
    "    return params\n",
    "\n",
    "# Saving\n",
    "if save:\n",
    "    save_model_params(params, resultdir)\n",
    "\n",
    "# Loading (uncomment when needed)\n",
    "# model_params = load_model_params(resultdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "K_cWIcoG0JL8",
    "outputId": "14ed2ce1-0a8a-4013-b6ef-bde0813eba52",
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Training of DeepONet\n",
    "start = time.time() # start time of training\n",
    "best_test_mse = float('inf')  # Initialize with infinity\n",
    "\n",
    "# Save initial model at 0th iteration\n",
    "save_model_params(params, resultdir, filename='model_params_best.pkl')\n",
    "print(\"Saved initial model at iteration 0\")\n",
    "\n",
    "for iteration in range(n_epochs):\n",
    "    indices = jax.random.permutation(jax.random.PRNGKey(0), num_samples)\n",
    "    batch_index = indices[0:bs]\n",
    "    inputs_train_shuffled = inputs_train[batch_index]\n",
    "    outputs_train_shuffled = outputs_train[batch_index]\n",
    "    target_values = outputs_train_shuffled\n",
    "    branch_inputs = inputs_train_shuffled\n",
    "    trunk_inputs = grid\n",
    "    params, opt_state, value = resnet_update(params, branch_inputs, trunk_inputs, target_values, opt_state)\n",
    "\n",
    "    if iteration % 1000 == 0:\n",
    "        \n",
    "        params_branch, params_trunk = params\n",
    "        predictions = DeepONet(params, branch_inputs, trunk_inputs)\n",
    "        test_mse = jnp.mean((predictions - target_values)**2)\n",
    "\n",
    "        # Compare current test error with the best so far\n",
    "        if test_mse < best_test_mse:\n",
    "            best_test_mse = test_mse\n",
    "            # Save the model as it's the best so far\n",
    "            save_model_params(params, resultdir, filename='model_params_best.pkl')\n",
    "            print(f\"New best model saved at iteration {iteration} with test MSE: {test_mse:.7f}\")\n",
    "\n",
    "        finish = time.time() - start\n",
    "        print(f\"Iteration: {iteration:3d}, Train loss: {objective(params, branch_inputs, trunk_inputs, target_values):.7f}, Test loss: {test_mse:.7f}, Best test loss: {best_test_mse:.7f}, Time: {finish:.2f}\")\n",
    "\n",
    "    iteration_list.append(iteration)\n",
    "    loss_list.append(objective(params, branch_inputs, trunk_inputs, target_values))\n",
    "    test_loss_list.append(test_mse)\n",
    "\n",
    "if save:\n",
    "    np.save(os.path.join(resultdir, 'iteration_list.npy'), np.asarray(iteration_list))\n",
    "    np.save(os.path.join(resultdir, 'loss_list.npy'), np.asarray(loss_list))\n",
    "    np.save(os.path.join(resultdir, 'test_loss_list.npy'), np.asarray(test_loss_list))\n",
    "\n",
    "# Plotting code remains the same\n",
    "plt.figure()\n",
    "plt.plot(iteration_list, loss_list, 'g', label='Training loss')\n",
    "plt.plot(iteration_list, test_loss_list, '-b', label='Test loss')\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(resultdir, 'loss_plot.pdf'))\n",
    "plt.show()\n",
    "    \n",
    "# end timer\n",
    "finish = time.time() - start\n",
    "print(\"Time (sec) to complete:\\n\" + str(finish))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Y6EIiKjo0JL8",
    "outputId": "b38f418a-6f26-48b2-da10-f06d9cde131e"
   },
   "outputs": [],
   "source": [
    "# params_branch, params_trunk = params\n",
    "# Load the best model parameters\n",
    "best_params = load_model_params(resultdir, filename='model_params_best.pkl')\n",
    "print(\"Loaded best model parameters\")\n",
    "\n",
    "# Predictions\n",
    "mse_list = []\n",
    "\n",
    "branch_inputs = inputs_test\n",
    "trunk_inputs = grid\n",
    "prediction = DeepONet(best_params, branch_inputs, trunk_inputs) # (bs, neval) \n",
    "\n",
    "inputs_save = inputs_test*inputs_std + inputs_mean\n",
    "outputs_save = outputs_test*outputs_std + outputs_mean\n",
    "prediction_save = prediction*outputs_std + outputs_mean\n",
    "\n",
    "save_dict = {'ground_motion': inputs_save, 'disp_pred': prediction_save,\\\n",
    "             'disp_target': outputs_save}\n",
    "\n",
    "io.savemat(resultdir+'/pred.mat', save_dict)\n",
    "\n",
    "for i in range(inputs_test.shape[0]):\n",
    "\n",
    "    branch_inputs = inputs_test[i].reshape(1, nx) \n",
    "    trunk_inputs = grid # (neval, 1) \n",
    "\n",
    "    prediction_i = DeepONet(best_params, branch_inputs, trunk_inputs) # (bs, neval)\n",
    "    target_i = outputs_test[i]\n",
    "\n",
    "    mse_i = np.mean((prediction_i - target_i)**2)\n",
    "    mse_list.append(mse_i.item())\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        print(colored('TEST SAMPLE '+str(i+1), 'red'))\n",
    "        \n",
    "        inputs_print = inputs_test[i]*inputs_std + inputs_mean\n",
    "        target_print = target_i*outputs_std + outputs_mean\n",
    "        prediction_print = prediction_i[0,:]*outputs_std + outputs_mean\n",
    "        \n",
    "        r2score = metrics.r2_score(target_print.flatten(), prediction_print.flatten())\n",
    "        relerror = np.linalg.norm(target_print- prediction_print) / np.linalg.norm(target_print)\n",
    "        r2score = float('%.4f'%r2score)\n",
    "        relerror = float('%.4f'%relerror)\n",
    "        print('Rel. L2 Error = '+str(relerror)+', R2 score = '+str(r2score))\n",
    "\n",
    "        fig = plt.figure(figsize=(15, 4))\n",
    "\n",
    "        # Adjust subplot parameters for better spacing\n",
    "        plt.subplots_adjust(left=0.1, bottom=0.1, right=0.9, top=0.9, wspace=0.4, hspace=0.3)\n",
    "        \n",
    "        # Input plot\n",
    "        ax = fig.add_subplot(1, 3, 1)\n",
    "        plt.plot(inputs_print)\n",
    "        plt.title('Input', fontsize=14)\n",
    "\n",
    "        # Output plot\n",
    "        ax = fig.add_subplot(1, 3, 2)\n",
    "        target = target_print\n",
    "        prediction = prediction_print\n",
    "        plt.plot(target, color='blue', linewidth=2)\n",
    "        plt.plot(prediction, color='red', linewidth=2)\n",
    "        plt.title('Output Field', fontsize=14)\n",
    "        plt.legend(['Target', 'Prediction'])\n",
    "\n",
    "        # Error plot\n",
    "        ax = fig.add_subplot(1, 3, 3)\n",
    "        error = target - prediction\n",
    "        plt.plot(error, color='magenta')\n",
    "        # plt.yscale(\"log\")  \n",
    "        plt.title('Absolute Error', fontsize=14)\n",
    "                         \n",
    "        plt.tight_layout()\n",
    "\n",
    "        if save == True:\n",
    "            plt.savefig(os.path.join(resultdir,'Test_Sample_'+str(i+1)+'.pdf'))\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "        if save == False:\n",
    "            plt.show()                 \n",
    "\n",
    "        print(colored('#'*230, 'green'))\n",
    "\n",
    "mse = sum(mse_list) / len(mse_list)\n",
    "print(\"Mean Squared Error Test :\\n\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(mse_list)\n",
    "hist, bins = np.histogram(data, bins=30)\n",
    "plt.hist(data, bins=bins, edgecolor='black')\n",
    "plt.xlabel('mean squared error')\n",
    "plt.ylabel('number of samples')\n",
    "plt.savefig(os.path.join(resultdir,'ErrorHistogram.pdf'))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 5604392,
     "sourceId": 9262123,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5620041,
     "sourceId": 9284520,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30762,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
